{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunohk/dataon_pj/blob/main/3_news_kpfbert_summary(%EB%89%B4%EC%8A%A4%EC%9A%94%EC%95%BD).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461376c8",
      "metadata": {
        "id": "461376c8"
      },
      "source": [
        "# Kpf-Bert를 이용한 뉴스기사 3줄요약 서비스  \n",
        "\n",
        "변곡점 기반 +- 1 day의 댓글 수가 많은 기사 3개씩 추출 및 요약\n",
        "\n",
        "목표: 여론이 뒤바뀌거나 언급량이 급증한 시기의 뉴스 요약본을 확인하여 이유를 추측\n",
        "정책과 연관있는 기사의 요약본을 통해 국회는 여론 파악\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIusVmF-gdj5",
        "outputId": "36a7dab6-7288-49e8-d9e5-c976dbd0fefc"
      },
      "id": "DIusVmF-gdj5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ./gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "fREuuQ9-hGvZ"
      },
      "id": "fREuuQ9-hGvZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc02c816",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc02c816",
        "outputId": "fb2d5f83-7c9a-41d6-a205-7ee27f595133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/PyTorchLightning/pytorch-lightning\n",
            "  Cloning https://github.com/PyTorchLightning/pytorch-lightning to /tmp/pip-req-build-cez40urf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-req-build-cez40urf\n",
            "  Resolved https://github.com/PyTorchLightning/pytorch-lightning to commit e7afe04ee86b64c76a5446088b3b75d9c275e5bf\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Encountered 22 file(s) that should have been pointers, but weren't:\n",
            "        .notebooks/course_UvA-DL/01-introduction-to-pytorch.ipynb\n",
            "        .notebooks/course_UvA-DL/02-activation-functions.ipynb\n",
            "        .notebooks/course_UvA-DL/03-initialization-and-optimization.ipynb\n",
            "        .notebooks/course_UvA-DL/04-inception-resnet-densenet.ipynb\n",
            "        .notebooks/course_UvA-DL/05-transformers-and-MH-attention.ipynb\n",
            "        .notebooks/course_UvA-DL/06-graph-neural-networks.ipynb\n",
            "        .notebooks/course_UvA-DL/07-deep-energy-based-generative-models.ipynb\n",
            "        .notebooks/course_UvA-DL/08-deep-autoencoders.ipynb\n",
            "        .notebooks/course_UvA-DL/09-normalizing-flows.ipynb\n",
            "        .notebooks/course_UvA-DL/10-autoregressive-image-modeling.ipynb\n",
            "        .notebooks/course_UvA-DL/11-vision-transformer.ipynb\n",
            "        .notebooks/flash_tutorials/electricity_forecasting.ipynb\n",
            "        .notebooks/flash_tutorials/image_classification.ipynb\n",
            "        .notebooks/flash_tutorials/tabular_classification.ipynb\n",
            "        .notebooks/flash_tutorials/text_classification.ipynb\n",
            "        .notebooks/lightning_examples/cifar10-baseline.ipynb\n",
            "        .notebooks/lightning_examples/datamodules.ipynb\n",
            "        .notebooks/lightning_examples/finetuning-scheduler.ipynb\n",
            "        .notebooks/lightning_examples/warp-drive.ipynb\n",
            "        .notebooks/templates/img-classify.ipynb\n",
            "        .notebooks/templates/simple.ipynb\n",
            "        .notebooks/templates/titanic.ipynb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning==2.2.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.2.0.dev0) (2023.6.0)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning==2.2.0.dev0)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning==2.2.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.2.0.dev0) (23.2)\n",
            "Requirement already satisfied: torch<4.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.2.0.dev0) (2.1.0+cu118)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning==2.2.0.dev0)\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.2.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.2.0.dev0) (4.5.0)\n",
            "Collecting pytorch-lightning (from lightning==2.2.0.dev0)\n",
            "  Downloading pytorch_lightning-2.1.0-py3-none-any.whl (774 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.6/774.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (3.8.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.2.0.dev0) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.2.0.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.2.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.2.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.2.0.dev0) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.12.0->lightning==2.2.0.dev0) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning==2.2.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.12.0->lightning==2.2.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: lightning\n",
            "  Building wheel for lightning (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightning: filename=lightning-2.2.0.dev0-py3-none-any.whl size=2001380 sha256=0459e6ebf679c09f722b4e34c2a07cf927b438a1cdb377fc7367ab96c3e415bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wp0bphez/wheels/1e/85/00/7ecb77532256b15c3067bcfe5f2d50d7fab3bea3d59f2520ab\n",
            "Successfully built lightning\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.2.0.dev0 lightning-utilities-0.9.0 pytorch-lightning-2.1.0 torchmetrics-1.2.0\n",
            "Collecting git+https://github.com/KPFBERT/kpfbert\n",
            "  Cloning https://github.com/KPFBERT/kpfbert to /tmp/pip-req-build-hqo5sx22\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/KPFBERT/kpfbert /tmp/pip-req-build-hqo5sx22\n",
            "  Resolved https://github.com/KPFBERT/kpfbert to commit 181684a769de40dc6ca6e420c18a685d6214b4d0\n",
            "\u001b[31mERROR: git+https://github.com/KPFBERT/kpfbert does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Collecting kss\n",
            "  Downloading kss-4.5.4.tar.gz (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting emoji==1.2.0 (from kss)\n",
            "  Downloading emoji-1.2.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from kss) (2023.6.3)\n",
            "Collecting pecab (from kss)\n",
            "  Downloading pecab-1.0.8.tar.gz (26.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from kss) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (1.23.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (9.0.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (7.4.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.1)\n",
            "Building wheels for collected packages: kss, pecab\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-4.5.4-py3-none-any.whl size=54465 sha256=e5e86a8f81d21120661fa0d5cae15fe999d28cef1dd7342c92b35dc5c0eff428\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/7b/ba/e620ef5d96a61cdd83bdee4c2bb4aec8a74de5d72fcbb00e80\n",
            "  Building wheel for pecab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pecab: filename=pecab-1.0.8-py3-none-any.whl size=26646664 sha256=30e23ae584cf114d6ec7c02084d88b9e6d9fc8a214b03fade2eac97df60d7d5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/6f/b4/ab61b8863d7d8b1409def8ae31adcaa089fa91b8d022ec309d\n",
            "Successfully built kss pecab\n",
            "Installing collected packages: emoji, pecab, kss\n",
            "Successfully installed emoji-1.2.0 kss-4.5.4 pecab-1.0.8\n"
          ]
        }
      ],
      "source": [
        "#@title Library\n",
        "\n",
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning\n",
        "!pip install git+https://github.com/KPFBERT/kpfbert\n",
        "!pip install transformers\n",
        "!pip install --upgrade pytorch-lightning\n",
        "!pip install torchmetrics\n",
        "!pip install kss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5521b37c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5521b37c",
        "outputId": "5694b80f-510e-45bb-8270-d389a5ad279d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from torch.nn.init import xavier_uniform_\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.functional import accuracy\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "import kss\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "pl.seed_everything(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjKhbn0X8omU",
        "outputId": "dc6e31a2-a901-445c-971d-f9e824e7cab0"
      },
      "id": "sjKhbn0X8omU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.8.6\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.13\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "anyio                            3.7.1\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array-record                     0.4.1\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.0\n",
            "attrs                            23.1.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.13.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.11.2\n",
            "bidict                           0.22.1\n",
            "bigframes                        0.8.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.2.2\n",
            "bqplot                           0.12.42\n",
            "branca                           0.6.0\n",
            "build                            1.0.3\n",
            "CacheControl                     0.13.1\n",
            "cachetools                       5.3.1\n",
            "catalogue                        2.0.10\n",
            "certifi                          2023.7.22\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.0\n",
            "chex                             0.1.7\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.7\n",
            "cmdstanpy                        1.2.0\n",
            "colorcet                         3.0.1\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.3\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.1.1\n",
            "cryptography                     41.0.4\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda11x                     11.0.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.2\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.4\n",
            "dask                             2023.8.1\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.1.1\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "diskcache                        5.6.3\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docutils                         0.18.1\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.8.1\n",
            "earthengine-api                  0.1.374\n",
            "easydict                         1.10\n",
            "ecos                             2.0.12\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "emoji                            1.2.0\n",
            "en-core-web-sm                   3.6.0\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.5.1\n",
            "etuples                          0.3.9\n",
            "exceptiongroup                   1.1.3\n",
            "fastai                           2.7.13\n",
            "fastcore                         1.5.29\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.18.1\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.12.4\n",
            "fiona                            1.9.5\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      23.5.26\n",
            "flax                             0.7.4\n",
            "folium                           0.14.0\n",
            "fonttools                        4.43.1\n",
            "frozendict                       2.3.8\n",
            "frozenlist                       1.4.0\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.4.0\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.4.3\n",
            "gdown                            4.6.6\n",
            "geemap                           0.28.2\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.17.3\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.0.0\n",
            "google-cloud-bigquery            3.10.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.22.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.12.2\n",
            "google-cloud-language            2.9.1\n",
            "google-cloud-resource-manager    1.10.4\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.6.0\n",
            "googleapis-common-protos         1.61.0\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.1\n",
            "greenlet                         3.0.0\n",
            "grpc-google-iam-v1               0.12.6\n",
            "grpcio                           1.59.0\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          3.4.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.2.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.35\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "huggingface-hub                  0.17.3\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   6.2.0\n",
            "idna                             3.4\n",
            "imageio                          2.31.5\n",
            "imageio-ffmpeg                   0.4.9\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "importlib-metadata               6.8.0\n",
            "importlib-resources              6.1.0\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "install                          1.3.5\n",
            "intel-openmp                     2023.2.0\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.17.4\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.1.2\n",
            "jax                              0.4.16\n",
            "jaxlib                           0.4.16+cuda11.cudnn86\n",
            "jeepney                          0.7.1\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.2\n",
            "joblib                           1.3.2\n",
            "jsonpickle                       3.0.2\n",
            "jsonschema                       4.19.1\n",
            "jsonschema-specifications        2023.7.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.4.0\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab-pygments              0.2.2\n",
            "jupyterlab-widgets               3.0.9\n",
            "kaggle                           1.5.16\n",
            "keras                            2.13.1\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "kss                              4.5.4\n",
            "langcodes                        3.3.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.3\n",
            "libclang                         16.0.6\n",
            "librosa                          0.10.1\n",
            "lida                             0.0.10\n",
            "lightgbm                         4.0.0\n",
            "lightning                        2.2.0.dev0\n",
            "lightning-utilities              0.9.0\n",
            "linkify-it-py                    2.0.2\n",
            "llmx                             0.0.15a0\n",
            "llvmlite                         0.39.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.3\n",
            "malloy                           2023.1056\n",
            "Markdown                         3.5\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.3\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.6\n",
            "matplotlib-venn                  0.11.9\n",
            "mdit-py-plugins                  0.4.0\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.3.1\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.7\n",
            "multidict                        6.0.4\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.0.0\n",
            "nbclient                         0.8.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.9.2\n",
            "nest-asyncio                     1.5.8\n",
            "networkx                         3.1\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.3\n",
            "numba                            0.56.4\n",
            "numexpr                          2.8.7\n",
            "numpy                            1.23.5\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.8.1.78\n",
            "openpyxl                         3.1.2\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.1.7\n",
            "orbax-checkpoint                 0.4.1\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        23.2\n",
            "pandas                           1.5.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.17.9\n",
            "pandas-stubs                     1.5.3.230304\n",
            "pandocfilters                    1.5.0\n",
            "panel                            1.2.3\n",
            "param                            1.13.0\n",
            "parso                            0.8.3\n",
            "parsy                            2.1\n",
            "partd                            1.4.1\n",
            "pathlib                          1.0.1\n",
            "pathy                            0.10.2\n",
            "patsy                            0.5.3\n",
            "pecab                            1.0.8\n",
            "peewee                           3.17.0\n",
            "pexpect                          4.8.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     3.11.0\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.3\n",
            "pluggy                           1.3.0\n",
            "polars                           0.17.3\n",
            "pooch                            1.7.0\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.9.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus-client                0.17.1\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.39\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.22.3\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          9.0.0\n",
            "pyasn1                           0.5.0\n",
            "pyasn1-modules                   0.3.0\n",
            "pybind11                         2.9.2\n",
            "pycocotools                      2.0.7\n",
            "pycparser                        2.21\n",
            "pyct                             0.5.0\n",
            "pydantic                         1.10.13\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1\n",
            "pygame                           2.5.2\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.7.2\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        23.2.0\n",
            "pyparsing                        3.1.1\n",
            "pyperclip                        1.8.2\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.0.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.14.2\n",
            "pytest                           7.4.2\n",
            "python-apt                       0.0.0\n",
            "python-box                       7.1.1\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.1\n",
            "python-utils                     3.8.1\n",
            "pytorch-lightning                2.1.0\n",
            "pytz                             2023.3.post1\n",
            "pyviz_comms                      3.0.0\n",
            "PyWavelets                       1.4.1\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            23.2.1\n",
            "qdldl                            0.1.7.post0\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.30.2\n",
            "regex                            2023.6.3\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.5.0\n",
            "rich                             13.6.0\n",
            "rpds-py                          0.10.6\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.0\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.3\n",
            "scooby                           0.7.4\n",
            "scs                              3.2.3\n",
            "seaborn                          0.12.2\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.2\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.2\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.4.0\n",
            "sniffio                          1.3.0\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.6.1\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.7\n",
            "sphinxcontrib-devhelp            1.0.5\n",
            "sphinxcontrib-htmlhelp           2.0.4\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.6\n",
            "sphinxcontrib-serializinghtml    1.1.9\n",
            "SQLAlchemy                       2.0.22\n",
            "sqlglot                          17.16.2\n",
            "sqlparse                         0.4.4\n",
            "srsly                            2.4.8\n",
            "stanio                           0.3.0\n",
            "statsmodels                      0.14.0\n",
            "sympy                            1.12\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.10.0\n",
            "tblib                            2.0.0\n",
            "tenacity                         8.2.3\n",
            "tensorboard                      2.13.0\n",
            "tensorboard-data-server          0.7.1\n",
            "tensorflow                       2.13.0\n",
            "tensorflow-datasets              4.9.3\n",
            "tensorflow-estimator             2.13.0\n",
            "tensorflow-gcs-config            2.13.0\n",
            "tensorflow-hub                   0.15.0\n",
            "tensorflow-io-gcs-filesystem     0.34.0\n",
            "tensorflow-metadata              1.14.0\n",
            "tensorflow-probability           0.20.1\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.3.0\n",
            "terminado                        0.17.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.1.12\n",
            "threadpoolctl                    3.2.0\n",
            "tifffile                         2023.9.26\n",
            "tinycss2                         1.2.1\n",
            "tokenizers                       0.14.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.0\n",
            "torch                            2.1.0+cu118\n",
            "torchaudio                       2.1.0+cu118\n",
            "torchdata                        0.7.0\n",
            "torchmetrics                     1.2.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu118\n",
            "tornado                          6.3.2\n",
            "tqdm                             4.66.1\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.34.1\n",
            "triton                           2.1.0\n",
            "tweepy                           4.13.0\n",
            "typer                            0.9.0\n",
            "types-pytz                       2023.3.1.1\n",
            "types-setuptools                 68.2.0.0\n",
            "typing_extensions                4.5.0\n",
            "tzlocal                          5.1\n",
            "uc-micro-py                      1.0.2\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.8\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.6.4\n",
            "Werkzeug                         3.0.0\n",
            "wheel                            0.41.2\n",
            "widgetsnbextension               3.6.6\n",
            "wordcloud                        1.9.2\n",
            "wrapt                            1.15.0\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.6.0\n",
            "xgboost                          2.0.0\n",
            "xlrd                             2.0.1\n",
            "xxhash                           3.4.1\n",
            "xyzservices                      2023.10.0\n",
            "yarl                             1.9.2\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.31\n",
            "zict                             3.0.0\n",
            "zipp                             3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2491afee",
      "metadata": {
        "id": "2491afee"
      },
      "outputs": [],
      "source": [
        "MAX_TOKEN_COUNT = 512\n",
        "N_EPOCHS = 5\n",
        "BATCH_SIZE = 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title tokenizer\n",
        "# kpfBERT 토크나이저는 형태소와 유사하게 잘 토크나이징을 하게 설계되어 있다.\n",
        "from transformers import BertTokenizerFast, BertModel\n",
        "\n",
        "BERT_MODEL_NAME = \"jinmang2/kpfbert\"\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
      ],
      "metadata": {
        "id": "B21nAhP3k6NS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "720e539c40c44b938781b29d249484bc",
            "39218e53cb8148e1a84049574e5e1d72",
            "c8bb3379bc1a44d2a038bad8e396bfbb",
            "1f94e590524c476db5ce8504e3c1f3d7",
            "df9f212af9554bba8a02187084b5acd2",
            "d6a3c1f1346a47dc86c79be0da246687",
            "33ed03c968f3468fa4ecc1c42a769d4f",
            "f6fc8516412d4ca8b0edeaf7e0ca34d3",
            "f4450456bf2944478ec7ed3e8708f4d3",
            "7caa9706140d431889e86c12baf86594",
            "afb092e154db484d931e2e5f87cacf58",
            "df633ae0d03a49b8bbda3cccd92d3859",
            "ef9c9ccc589b4559b84db57414a39b58",
            "86c673d92d174deb8ab837236e1ed938",
            "c209439ab3da4c98b85c14c92b5686fb",
            "778d16ea7a534a9992439316ea123899",
            "090a5daa94fb46508c5dbfb4bac785e6",
            "fd88c3928b8947f68bb739ecc4e669a1",
            "3b58cb0cc33f46e69e8b8613b807c243",
            "5f4b9bbc9a4a404aaa502777acf944ba",
            "2f61975ac3584925bc624510a7e6dbfc",
            "d28a63c4fbd748808b558a9c0d95a0d4",
            "16c4a09e99d04297bb76eb399700110a",
            "5eccfb7a4fe34d5ebf8aeec825684e91",
            "da3f8b1a556349a1b3bc2d82aef8e864",
            "e4c38d6df7964f319cab9a90f8cb4f79",
            "70b74e18f8f543f1b18015b88b0faee2",
            "06321fdb7dc548358bed5a8273ccc732",
            "554ac44e5694468eb4d06d76bd7d1923",
            "5bc249925b2d4533be278b519b3989f3",
            "23d8101cec3b475792d8e34e854b353d",
            "3a2224e3d1474b3ebe28eca39ab83420",
            "e6ca6800c36e4a70b3965bd085aa9353"
          ]
        },
        "outputId": "ff1bf2cc-e97d-4c81-b183-419ff5d129f9"
      },
      "id": "B21nAhP3k6NS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/335 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "720e539c40c44b938781b29d249484bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/276k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df633ae0d03a49b8bbda3cccd92d3859"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16c4a09e99d04297bb76eb399700110a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eafb0f2",
      "metadata": {
        "id": "3eafb0f2"
      },
      "outputs": [],
      "source": [
        "class SummDataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        tokenizer: BertTokenizer,\n",
        "        max_token_len: int = 512\n",
        "    ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        data_row = self.data.iloc[index]\n",
        "\n",
        "        tokenlist = []\n",
        "        for sent in data_row.article_original:\n",
        "            tokenlist.append(tokenizer(\n",
        "                text = sent,\n",
        "                add_special_tokens = True)) #, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "        src = [] # 토크나이징 된 전체 문단\n",
        "        labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
        "        segs = []  #각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
        "        clss = []  #[CLS]토큰의 포지션값을 지정\n",
        "\n",
        "        odd = 0\n",
        "        for tkns in tokenlist:\n",
        "            if odd > 1 : odd = 0\n",
        "            clss = clss + [len(src)]\n",
        "            src = src + tkns['input_ids']\n",
        "            segs = segs + [odd] * len(tkns['input_ids'])\n",
        "            if tokenlist.index(tkns) in data_row.extractive :\n",
        "                labels = labels + [1]\n",
        "            else:\n",
        "                labels = labels + [0]\n",
        "            odd += 1\n",
        "\n",
        "            #truncation\n",
        "            if len(src) == MAX_TOKEN_COUNT:\n",
        "                break\n",
        "            elif len(src) > MAX_TOKEN_COUNT:\n",
        "                src = src[:self.max_token_len - 1] + [src[-1]]\n",
        "                segs = segs[:self.max_token_len]\n",
        "                break\n",
        "\n",
        "        #padding\n",
        "        if len(src) < MAX_TOKEN_COUNT:\n",
        "            src = src + [0]*(self.max_token_len - len(src))\n",
        "            segs = segs + [0]*(self.max_token_len - len(segs))\n",
        "\n",
        "        if len(clss) < MAX_TOKEN_COUNT:\n",
        "            clss = clss + [-1]*(self.max_token_len - len(clss))\n",
        "        if len(labels) < MAX_TOKEN_COUNT:\n",
        "            labels = labels + [0]*(self.max_token_len - len(labels))\n",
        "\n",
        "        return dict(\n",
        "            src = torch.tensor(src),\n",
        "            segs = torch.tensor(segs),\n",
        "            clss = torch.tensor(clss),\n",
        "            labels= torch.FloatTensor(labels)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3ed02d0",
      "metadata": {
        "id": "a3ed02d0"
      },
      "outputs": [],
      "source": [
        "class SummDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, train_df, test_df, val_df, tokenizer, batch_size=1, max_token_len=512):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_df = train_df\n",
        "        self.test_df = test_df\n",
        "        self.val_df = val_df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = SummDataset(\n",
        "            self.train_df,\n",
        "            self.tokenizer,\n",
        "            self.max_token_len\n",
        "        )\n",
        "\n",
        "        self.test_dataset = SummDataset(\n",
        "            self.test_df,\n",
        "            self.tokenizer,\n",
        "            self.max_token_len\n",
        "        )\n",
        "\n",
        "        self.val_dataset = SummDataset(\n",
        "            self.val_df,\n",
        "            self.tokenizer,\n",
        "            self.max_token_len\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=8 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=8 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=8 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324f65c2",
      "metadata": {
        "id": "324f65c2"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout, dim, max_len=5000):\n",
        "        pe = torch.zeros(max_len, dim)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) *\n",
        "                              -(math.log(10000.0) / dim)))\n",
        "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.register_buffer('pe', pe)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, emb, step=None):\n",
        "        emb = emb * math.sqrt(self.dim)\n",
        "        if (step):\n",
        "            emb = emb + self.pe[:, step][:, None, :]\n",
        "\n",
        "        else:\n",
        "            emb = emb + self.pe[:, :emb.size(1)]\n",
        "        emb = self.dropout(emb)\n",
        "        return emb\n",
        "\n",
        "    def get_emb(self, emb):\n",
        "        return self.pe[:, :emb.size(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d7d27c",
      "metadata": {
        "id": "34d7d27c"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, d_ff, dropout):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadedAttention(\n",
        "            heads, d_model, dropout=dropout)\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, iter, query, inputs, mask):\n",
        "        if (iter != 0):\n",
        "            input_norm = self.layer_norm(inputs)\n",
        "        else:\n",
        "            input_norm = inputs\n",
        "\n",
        "        mask = mask.unsqueeze(1)\n",
        "        context = self.self_attn(input_norm, input_norm, input_norm,\n",
        "                                 mask=mask)\n",
        "        out = self.dropout(context) + inputs\n",
        "        return self.feed_forward(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da055122",
      "metadata": {
        "id": "da055122"
      },
      "outputs": [],
      "source": [
        "class ExtTransformerEncoder(nn.Module):\n",
        "    def __init__(self, hidden_size=768, d_ff=2048, heads=8, dropout=0.2, num_inter_layers=2):\n",
        "        super(ExtTransformerEncoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_inter_layers = num_inter_layers\n",
        "        self.pos_emb = PositionalEncoding(dropout, hidden_size)\n",
        "        self.transformer_inter = nn.ModuleList(\n",
        "            [TransformerEncoderLayer(hidden_size, heads, d_ff, dropout)\n",
        "            for _ in range(num_inter_layers)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
        "        self.wo = nn.Linear(hidden_size, 1, bias=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, top_vecs, mask):\n",
        "        \"\"\" See :obj:`EncoderBase.forward()`\"\"\"\n",
        "\n",
        "        batch_size, n_sents = top_vecs.size(0), top_vecs.size(1)\n",
        "        pos_emb = self.pos_emb.pe[:, :n_sents]\n",
        "        x = top_vecs * mask[:, :, None].float()\n",
        "        x = x + pos_emb\n",
        "\n",
        "        for i in range(self.num_inter_layers):\n",
        "            x = self.transformer_inter[i](i, x, x, ~mask)\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "        sent_scores = self.sigmoid(self.wo(x))\n",
        "        sent_scores = sent_scores.squeeze(-1) * mask.float()\n",
        "\n",
        "        return sent_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f635acc3",
      "metadata": {
        "id": "f635acc3"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\" A two-layer Feed-Forward-Network with residual layer norm.\n",
        "\n",
        "    Args:\n",
        "        d_model (int): the size of input for the first-layer of the FFN.\n",
        "        d_ff (int): the hidden layer size of the second-layer\n",
        "            of the FNN.\n",
        "        dropout (float): dropout probability in :math:`[0, 1)`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def gelu(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        inter = self.dropout_1(self.gelu(self.w_1(self.layer_norm(x))))\n",
        "        output = self.dropout_2(self.w_2(inter))\n",
        "        return output + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6397849c",
      "metadata": {
        "id": "6397849c"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Head Attention module from\n",
        "    \"Attention is All You Need\"\n",
        "    :cite:`DBLP:journals/corr/VaswaniSPUJGKP17`.\n",
        "\n",
        "    Similar to standard `dot` attention but uses\n",
        "    multiple attention distributions simulataneously\n",
        "    to select relevant items.\n",
        "\n",
        "    .. mermaid::\n",
        "\n",
        "       graph BT\n",
        "          A[key]\n",
        "          B[value]\n",
        "          C[query]\n",
        "          O[output]\n",
        "          subgraph Attn\n",
        "            D[Attn 1]\n",
        "            E[Attn 2]\n",
        "            F[Attn N]\n",
        "          end\n",
        "          A --> D\n",
        "          C --> D\n",
        "          A --> E\n",
        "          C --> E\n",
        "          A --> F\n",
        "          C --> F\n",
        "          D --> O\n",
        "          E --> O\n",
        "          F --> O\n",
        "          B --> O\n",
        "\n",
        "    Also includes several additional tricks.\n",
        "\n",
        "    Args:\n",
        "       head_count (int): number of parallel heads\n",
        "       model_dim (int): the dimension of keys/values/queries,\n",
        "           must be divisible by head_count\n",
        "       dropout (float): dropout parameter\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, head_count, model_dim, dropout=0.1, use_final_linear=True):\n",
        "        assert model_dim % head_count == 0\n",
        "        self.dim_per_head = model_dim // head_count\n",
        "        self.model_dim = model_dim\n",
        "\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        self.head_count = head_count\n",
        "\n",
        "        self.linear_keys = nn.Linear(model_dim,\n",
        "                                     head_count * self.dim_per_head)\n",
        "        self.linear_values = nn.Linear(model_dim,\n",
        "                                       head_count * self.dim_per_head)\n",
        "        self.linear_query = nn.Linear(model_dim,\n",
        "                                      head_count * self.dim_per_head)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.use_final_linear = use_final_linear\n",
        "        if (self.use_final_linear):\n",
        "            self.final_linear = nn.Linear(model_dim, model_dim)\n",
        "\n",
        "    def forward(self, key, value, query, mask=None,\n",
        "                layer_cache=None, type=None, predefined_graph_1=None):\n",
        "        \"\"\"\n",
        "        Compute the context vector and the attention vectors.\n",
        "\n",
        "        Args:\n",
        "           key (`FloatTensor`): set of `key_len`\n",
        "                key vectors `[batch, key_len, dim]`\n",
        "           value (`FloatTensor`): set of `key_len`\n",
        "                value vectors `[batch, key_len, dim]`\n",
        "           query (`FloatTensor`): set of `query_len`\n",
        "                 query vectors  `[batch, query_len, dim]`\n",
        "           mask: binary mask indicating which keys have\n",
        "                 non-zero attention `[batch, query_len, key_len]`\n",
        "        Returns:\n",
        "           (`FloatTensor`, `FloatTensor`) :\n",
        "\n",
        "           * output context vectors `[batch, query_len, dim]`\n",
        "           * one of the attention vectors `[batch, query_len, key_len]`\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = key.size(0)\n",
        "        dim_per_head = self.dim_per_head\n",
        "        head_count = self.head_count\n",
        "        key_len = key.size(1)\n",
        "        query_len = query.size(1)\n",
        "\n",
        "        def shape(x):\n",
        "            \"\"\"  projection \"\"\"\n",
        "            return x.view(batch_size, -1, head_count, dim_per_head) \\\n",
        "                .transpose(1, 2)\n",
        "\n",
        "        def unshape(x):\n",
        "            \"\"\"  compute context \"\"\"\n",
        "            return x.transpose(1, 2).contiguous() \\\n",
        "                .view(batch_size, -1, head_count * dim_per_head)\n",
        "\n",
        "        # 1) Project key, value, and query.\n",
        "        if layer_cache is not None:\n",
        "            if type == \"self\":\n",
        "                query, key, value = self.linear_query(query), \\\n",
        "                                    self.linear_keys(query), \\\n",
        "                                    self.linear_values(query)\n",
        "\n",
        "                key = shape(key)\n",
        "                value = shape(value)\n",
        "\n",
        "                if layer_cache is not None:\n",
        "                    device = key.device\n",
        "                    if layer_cache[\"self_keys\"] is not None:\n",
        "                        key = torch.cat(\n",
        "                            (layer_cache[\"self_keys\"].to(device), key),\n",
        "                            dim=2)\n",
        "                    if layer_cache[\"self_values\"] is not None:\n",
        "                        value = torch.cat(\n",
        "                            (layer_cache[\"self_values\"].to(device), value),\n",
        "                            dim=2)\n",
        "                    layer_cache[\"self_keys\"] = key\n",
        "                    layer_cache[\"self_values\"] = value\n",
        "            elif type == \"context\":\n",
        "                query = self.linear_query(query)\n",
        "                if layer_cache is not None:\n",
        "                    if layer_cache[\"memory_keys\"] is None:\n",
        "                        key, value = self.linear_keys(key), \\\n",
        "                                     self.linear_values(value)\n",
        "                        key = shape(key)\n",
        "                        value = shape(value)\n",
        "                    else:\n",
        "                        key, value = layer_cache[\"memory_keys\"], \\\n",
        "                                     layer_cache[\"memory_values\"]\n",
        "                    layer_cache[\"memory_keys\"] = key\n",
        "                    layer_cache[\"memory_values\"] = value\n",
        "                else:\n",
        "                    key, value = self.linear_keys(key), \\\n",
        "                                 self.linear_values(value)\n",
        "                    key = shape(key)\n",
        "                    value = shape(value)\n",
        "        else:\n",
        "            key = self.linear_keys(key)\n",
        "            value = self.linear_values(value)\n",
        "            query = self.linear_query(query)\n",
        "            key = shape(key)\n",
        "            value = shape(value)\n",
        "\n",
        "        query = shape(query)\n",
        "\n",
        "        key_len = key.size(2)\n",
        "        query_len = query.size(2)\n",
        "\n",
        "        # 2) Calculate and scale scores.\n",
        "        query = query / math.sqrt(dim_per_head)\n",
        "        scores = torch.matmul(query, key.transpose(2, 3))\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1).expand_as(scores)\n",
        "            scores = scores.masked_fill(mask, -1e18) # how can i fix it to use fp16...\n",
        "\n",
        "        # 3) Apply attention dropout and compute context vectors.\n",
        "\n",
        "        attn = self.softmax(scores)\n",
        "\n",
        "        if (not predefined_graph_1 is None):\n",
        "            attn_masked = attn[:, -1] * predefined_graph_1\n",
        "            attn_masked = attn_masked / (torch.sum(attn_masked, 2).unsqueeze(2) + 1e-9)\n",
        "\n",
        "            attn = torch.cat([attn[:, :-1], attn_masked.unsqueeze(1)], 1)\n",
        "\n",
        "        drop_attn = self.dropout(attn)\n",
        "        if (self.use_final_linear):\n",
        "            context = unshape(torch.matmul(drop_attn, value))\n",
        "            output = self.final_linear(context)\n",
        "            return output\n",
        "        else:\n",
        "            context = torch.matmul(drop_attn, value)\n",
        "            return context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d68483e4",
      "metadata": {
        "id": "d68483e4"
      },
      "outputs": [],
      "source": [
        "class Summarizer(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, n_training_steps=None, n_warmup_steps=None):\n",
        "        super().__init__()\n",
        "        self.max_pos = 512\n",
        "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME) #, return_dict=True)\n",
        "        self.ext_layer = ExtTransformerEncoder()\n",
        "        self.n_training_steps = n_training_steps\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "        self.loss = nn.BCELoss(reduction='none')\n",
        "\n",
        "        self.training_step_outputs = []\n",
        "        self.validation_step_outputs = []\n",
        "        self.test_step_outputs = []\n",
        "\n",
        "        for p in self.ext_layer.parameters():\n",
        "            if p.dim() > 1:\n",
        "                xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src, segs, clss, labels=None): #, input_ids, attention_mask, labels=None):\n",
        "\n",
        "        mask_src = ~(src == 0) #1 - (src == 0)\n",
        "        mask_cls = ~(clss == -1) #1 - (clss == -1)\n",
        "\n",
        "        top_vec = self.bert(src, token_type_ids=segs, attention_mask=mask_src)\n",
        "        top_vec = top_vec.last_hidden_state\n",
        "\n",
        "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n",
        "        sents_vec = sents_vec * mask_cls[:, :, None].float()\n",
        "\n",
        "        sent_scores = self.ext_layer(sents_vec, mask_cls).squeeze(-1)\n",
        "\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss(sent_scores, labels)\n",
        "\n",
        "            loss = (loss * mask_cls.float()).sum() / len(labels)\n",
        "\n",
        "        return loss, sent_scores\n",
        "\n",
        "    def step(self, batch):\n",
        "\n",
        "        src = batch['src']\n",
        "        if len(batch['labels']) > 0 :\n",
        "            labels = batch['labels']\n",
        "        else:\n",
        "            labels = None\n",
        "        segs = batch['segs']\n",
        "        clss = batch['clss']\n",
        "\n",
        "        loss, sent_scores = self(src, segs, clss, labels)\n",
        "\n",
        "        return loss, sent_scores, labels\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        loss, sent_scores, labels = self.step(batch)\n",
        "        self.training_step_outputs.append(loss)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "\n",
        "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        loss, sent_scores, labels = self.step(batch)\n",
        "        self.validation_step_outputs.append(loss)\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "\n",
        "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        loss, sent_scores, labels = self.step(batch)\n",
        "        self.test_step_outputs.append(loss)\n",
        "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "\n",
        "        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "\n",
        "        epoch_average = torch.stack(self.training_step_outputs).mean()\n",
        "        self.log(\"training_epoch_average\", epoch_average)\n",
        "        self.training_step_outputs.clear()  # free memory\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        epoch_average = torch.stack(self.validation_step_outputs).mean()\n",
        "        self.log(\"validation_epoch_average\", epoch_average)\n",
        "        self.validation_step_outputs.clear()  # free memory\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        epoch_average = torch.stack(self.test_step_outputs).mean()\n",
        "        self.log(\"test_epoch_average\", epoch_average)\n",
        "        self.test_step_outputs.clear()  # free memory\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "\n",
        "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
        "\n",
        "        steps_per_epoch=len(train_df) // BATCH_SIZE\n",
        "        total_training_steps = steps_per_epoch * N_EPOCHS\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=steps_per_epoch,\n",
        "            num_training_steps=total_training_steps\n",
        "        )\n",
        "\n",
        "        return dict(\n",
        "            optimizer=optimizer,\n",
        "            lr_scheduler=dict(\n",
        "                scheduler=scheduler,\n",
        "                interval='step'\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Summarizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "73c43911a06045a8a72237160d91e57b",
            "227ca31dfef8478a9fee885d4ddca726",
            "cad773d0ba24409d864f5cb16c402caa",
            "3a2de65639b54cf5a451c09aee55a034",
            "c922e8cead9944ba87b63969393d51b2",
            "7e823f10a73e4d1fa5da2ad2c32d4a02",
            "279f485de91f4485bfb60a11cbad488b",
            "b3fb6c3d8db04d8eb3e82bd80c5d4b96",
            "186e38a464074a36a0a930aec1b80159",
            "83ee1e22520b403eaf42f9318a8c6480",
            "6180ad606d0b40d8b4e6852f8bbf6547",
            "bf3f0b719e5244f98ab53eaac22b59c7",
            "8830b67dc09d4abfba80c82f6d580fb6",
            "8e6d6fa0b27f4e219fcd9e42ac1e13c0",
            "32d1ada2519b47efb463667521d9e000",
            "1d3e559476c74ca098928670eb06ba02",
            "70f8fdd256ee45d3a43dc3cf1545f0b5",
            "b54fc55339f1438cab27e1f5a9c849f7",
            "2eba77d1034d45bbbe8e243d3c3a0aeb",
            "846990c171c2407686ae9467078061f1",
            "5e9a4029835e49d4811ae0ae6c57b531",
            "51e024e29aea40139530f4603c33c211"
          ]
        },
        "id": "IujDr3YWqnbS",
        "outputId": "4eb96a28-7cb2-44f4-b555-adb35deb6149"
      },
      "id": "IujDr3YWqnbS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73c43911a06045a8a72237160d91e57b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf3f0b719e5244f98ab53eaac22b59c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at jinmang2/kpfbert and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Load"
      ],
      "metadata": {
        "id": "8Az67wLgiz9t"
      },
      "id": "8Az67wLgiz9t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af18eb3c",
      "metadata": {
        "id": "af18eb3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927a7893-9ef3-42d0-87ec-4414227b015f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at jinmang2/kpfbert and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Summarizer(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(36440, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (ext_layer): ExtTransformerEncoder(\n",
              "    (pos_emb): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (transformer_inter): ModuleList(\n",
              "      (0-1): 2 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiHeadedAttention(\n",
              "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (softmax): Softmax(dim=-1)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (feed_forward): PositionwiseFeedForward(\n",
              "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
              "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
              "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (loss): BCELoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "PATH = './gdrive/MyDrive/01_공모전/2023_News/5_Presentation/제출자료/모델/2_kpfbertsumm_trained_model.pt'\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "trained_model = Summarizer()\n",
        "trained_model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # 사용할 GPU 장치 번호를 선택합니다.\n",
        "trained_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b793b85",
      "metadata": {
        "id": "1b793b85"
      },
      "outputs": [],
      "source": [
        "#@title 뉴스데이터 preprocess\n",
        "\n",
        "def data_process(text):\n",
        "    # 문장 분리 하고,\n",
        "    sents = kss.split_sentences(text)\n",
        "\n",
        "    #데이터 가공하고,\n",
        "    tokenlist = []\n",
        "    for sent in sents:\n",
        "        tokenlist.append(tokenizer(\n",
        "            text = sent,\n",
        "            add_special_tokens = True)) #, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "    src = [] # 토크나이징 된 전체 문단\n",
        "    labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
        "    segs = []  #각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
        "    clss = []  #[CLS]토큰의 포지션값을 지정\n",
        "\n",
        "    odd = 0\n",
        "\n",
        "    for tkns in tokenlist:\n",
        "\n",
        "        if odd > 1 : odd = 0\n",
        "        clss = clss + [len(src)]\n",
        "        src = src + tkns['input_ids']\n",
        "        segs = segs + [odd] * len(tkns['input_ids'])\n",
        "        odd += 1\n",
        "\n",
        "        #truncation\n",
        "        if len(src) == MAX_TOKEN_COUNT:\n",
        "            break\n",
        "        elif len(src) > MAX_TOKEN_COUNT:\n",
        "            src = src[:MAX_TOKEN_COUNT - 1] + [src[-1]]\n",
        "            segs = segs[:MAX_TOKEN_COUNT]\n",
        "            break\n",
        "\n",
        "    #padding\n",
        "    if len(src) < MAX_TOKEN_COUNT:\n",
        "        src = src + [0]*(MAX_TOKEN_COUNT - len(src))\n",
        "        segs = segs + [0]*(MAX_TOKEN_COUNT - len(segs))\n",
        "\n",
        "    if len(clss) < MAX_TOKEN_COUNT:\n",
        "        clss = clss + [-1]*(MAX_TOKEN_COUNT - len(clss))\n",
        "\n",
        "    return dict(\n",
        "        sents = sents, #정답 출력을 위해...\n",
        "        src = torch.tensor(src).cuda(),\n",
        "        segs = torch.tensor(segs).cuda(),\n",
        "        clss = torch.tensor(clss).cuda(),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88c5a964",
      "metadata": {
        "id": "88c5a964"
      },
      "outputs": [],
      "source": [
        "def summarize_test(text):\n",
        "    data = data_process(text.replace('\\n',''))\n",
        "\n",
        "    #trained_model에 넣어 결과값 반환\n",
        "    _, rtn = trained_model(data['src'].unsqueeze(0), data['segs'].unsqueeze(0), data['clss'].unsqueeze(0))\n",
        "    rtn = rtn.squeeze()\n",
        "\n",
        "    # 예측 결과값을 받기 위한 프로세스\n",
        "    rtn_sort, idx = rtn.sort(descending = True)\n",
        "\n",
        "    rtn_sort = rtn_sort.tolist()\n",
        "    idx = idx.tolist()\n",
        "\n",
        "    end_idx = rtn_sort.index(0)\n",
        "\n",
        "    rtn_sort = rtn_sort[:end_idx]\n",
        "    idx = idx[:end_idx]\n",
        "\n",
        "    if len(idx) > 3:\n",
        "        rslt = idx[:3]\n",
        "    else:\n",
        "        rslt = idx\n",
        "\n",
        "    summ = []\n",
        "    # print(' *** 입력한 문단의 요약문은 ...')\n",
        "    for i, r in enumerate(rslt):\n",
        "        summ.append(data['sents'][r])\n",
        "        print('[', i+1, ']', summ[i])\n",
        "\n",
        "    return summ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load news data"
      ],
      "metadata": {
        "id": "I4hsjJd9MSLF"
      },
      "id": "I4hsjJd9MSLF"
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = pd.read_excel('./gdrive/MyDrive/01_공모전/2023_News/5_Presentation/제출자료/데이터/Processed_Data/3_news_summ_pre.xlsx')\n",
        "df = raw_df"
      ],
      "metadata": {
        "id": "YotZNhrKMU40"
      },
      "id": "YotZNhrKMU40",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#processing\n",
        "#combine title + content\n",
        "# df['summary'] = df['제목'] + df['내용'].astype(str)\n",
        "# keep_cols = ['작성일','작성자','제목','내용']\n",
        "# df = raw_df[keep_cols]\n",
        "# df.columns = ['Date', 'Publisher', 'Title', 'Text']\n",
        "df['Text'] = df['Text'].str.replace('…', '').str.replace('\\\\', '')"
      ],
      "metadata": {
        "id": "-Wv7iu2zNAse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6e3dda-c54f-4ac6-9307-882a75e65963"
      },
      "id": "-Wv7iu2zNAse",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-c8d47bf94919>:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df['Text'] = df['Text'].str.replace('…', '').str.replace('\\\\', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1= df['Text'][0]\n",
        "test1\n"
      ],
      "metadata": {
        "id": "nRGrnzExWxi5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "91c5dbd8-4699-4639-a12b-b85631fabd84"
      },
      "id": "nRGrnzExWxi5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"가르치려 한 오만함, 청년과 단절 원인\" 반성 \"박원순 피해자 제대로 된 사과와 반성 이뤄지지 않았어\" 이소영 의원을 비롯한 더불어민주당 2030의원들이 9일 오전 서울 여의도 국회 소통관에서 \\'더불어민주당 2030의원 입장문\\' 발표를 기자회견을 하고 있다. 2021.4.9/뉴스1 © News1 박세연 기자 (서울=뉴스1) 서혜림 기자 = 더불어민주당 2030대 의원들은 9일 입장문을 내고 \"돌아선 국민의 마음의 원인은 저희를 포함한 민주당의 착각과 오판에 있었음을 자인한다\"고 말했다. 민주당 오영환·이소영·장경태·장철민·전용기 의원은 이날 오전 국회 소통관에서 기자회견을 열고 \"선거 유세 현장과 삶의 현장에서 만난 20대 30대 청년들은 민주당에 싸늘하고 무관심했고 지난 1년 동안 많은 분의 마음이 돌아섰음을 현장에서 느꼈다\"고 말했다. 이들은 \"이번 재보궐선거를 치르게 된 원인이 우리 당 공직자의 성 비위 문제였음에도 불구하고 우리 당은 당헌·당규를 개정해 후보를 내고 피해자에 대한 제대로 된 사죄도 없었다\"며 \"당내 2차 가해를 적극적으로 막는 조처를 하지 않았다. 이 문제를 회피하고 외면할 수 있지 않을까 하는 오만함이었다\"고 비판했다. 아울러 \"추미애-윤석열 갈등으로 점철된 (검찰개혁) 추진과정에서 국민들의 공감대를 잃었고 오만과 독선으로 보일 수 있는 행동들이 국민들께 피로와 염증을 느끼게 했음에도 그것이 개혁적 태도라 오판했다\"고 말했다. 또 \"조국 전 장관이 검찰개혁의 대명사라고 생각했고 검찰의 부당한 압박에 밀리면 안 된다고 판단했지만 그 과정에서 수많은 국민들이 분노하고 분열했다\"며 \"오히려 검찰개혁의 당위성과 동력을 잃은 것은 아닌가 뒤돌아보고 반성한다\"고 말했다. 이들은 \"내로남불의 비판을 촉발시킨 여당 인사들의 재산 증식과 이중적 태도에도 국민에게 들이대는 냉정한 잣대와 조치를 들이대지 못하고 억울해하며 변명으로 일관해왔음을 인정한다\"며 \"분노하셨을 국민께 사과드린다\"고 말했다. 의원들은 \"민주화를 이뤄낸 국민의 위대함은 민주당만의 전유물이 아님을 잊은 건 아닌지 아프게 성찰한다\"며 \"청년없는 청년 정책을 펼친 것도 청년들을 낙심하게 만들었다\"고 했다. 또 \"많은 청년들의 분노를 산 소위 \\'인국공 문제\\' 역시 청년들이 분노하는 이유를 제대로 살피지 않았고 우리가 지향하는 가치를 그분들께 가르치려고 한 오만함이 청년들과 민주당의 소통을 단절시킨 한 원인이었다\"고 아프게 자평했다. 이들은 \"재보궐선거 참패 원인을 야당, 언론,국민,청년 탓으로 돌리는 목소리에 저희는 동의할 수 없다\"며 \"지금은 오로지 우리의 말과 선택과 행동을 되돌아봐야 하는 시간\"이라고 말했다. 청년 정치인으로서의 반성도 이어졌다. 이들은 \"지난 1년간 우리는 경험이 부족한 초선의원임을 핑계 삼아 어렵고 민감한 문제에 용기 있게 나서지 못했고 정부와 지도부의 판단에 의존했다\"며 \"가장 혁신적이고 당내의 주류적 관행과 기득권 구조에 비판적이었어야할 우리 청년 의원들까지도 오만했고 게을렀고 용기가 없었다\"고 자책했다. 또 \"청년의 상황과 입장을 더 근본적으로 이해하고 국방, 부동산, 교육, 경제 등 모든 분야 정책에 청년들의 현실과 감수성을 반영하겠다\"고 약속했다. 의원들은 입장문 발표가 끝난 후 기자들과 만난 자리에서도 반성을 이어갔다. 특히 \\'조 전 장관과 관련해서 민주당의 대응이 구체적으로 어떻게 잘못됐는지\\'를 묻는 말에 오 의원은 \"그 부분에 대해서 국민들께서 사과를 요구하면 사과할 용의도 있다\"며 \"그 부분에 대해 결과적으로 분노하고 분열되고 촉발되었다고 생각하기 때문에 반성하는 것을 분명히 해야 한다\"고 밝혔다. 또 이번 보궐선거 원인이 된 고 박원순 전 서울시장 성추행 사건과 관련해 당내 미온적 반응과 관련한 입장을 묻는 말에 이 의원은 \"지난 9개월동안 (박 전 시장 피해자에 대해) 제대로 된 사과와 반성과 대책, 적절한 대응이 이뤄지지 않았다고 본다\"며 \"선거가 가까워져서야 그런 것이 이루어졌고 선거 과정에서도 소극적으로 대처했다\"고 고백했다. 이어 \"당은 지난 9개월동안 우리의 대응과 많은 문제들에 대해서 복기해야한다고 생각한다\"며 \"복기에 기반해 우리가 무엇을 잘못했고, 무엇을 하지 말았어야 했는지 진솔한 고백이 필요하다고 생각하며, (혁신안을) 요구할 예정\"이라고 말했다. 일각에서 제기되는 \\'보궐선거에 책임 있는 인사들이 당 지도부 선거에 나오지 않아야 한다\\'는 의견과 관련해서는 이 의원은 \"(세력) 교체 차원에서는 (2030 의원들이) 의견이나 입장을 내는 것도 열어두고 논의할 예정\"이라고 밝혔다. 또 \"오늘 발표한 진단과 반성에 그치지 않고 실제로 움직이는 모습을 보여주려고 하며, 곧 보여드릴 것\"이라고 말했다. 다만 장 의원은 \"선거 책임은 모두가 져야 한다고 본다. 특정 인물을 지목하거나, 그분들에게만 책임이 있다고 생각하지는 않는다. 그동안의 관행이나 오만과 독선으로 비춰질 수 있는 부분에 대해서 스스로 문제를 제기하는 반성이 담긴 것\"이라고 설명했다. suhhyerim777@news1.kr'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b43921",
      "metadata": {
        "id": "a1b43921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea061f62-9894-47dd-8f95-35be9db5f402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Because there's no supported C++ morpheme analyzer, Kss will take pecab as a backend. :D\n",
            "For your information, Kss also supports mecab backend.\n",
            "We recommend you to install mecab or konlpy.tag.Mecab for faster execution of Kss.\n",
            "Please refer to following web sites for details:\n",
            "- mecab: https://github.com/hyunwoongko/python-mecab-kor\n",
            "- konlpy.tag.Mecab: https://konlpy.org/en/latest/api/konlpy.tag/#mecab-class\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1 ] \"가르치려 한 오만함, 청년과 단절 원인\" 반성 \"박원순 피해자 제대로 된 사과와 반성 이뤄지지 않았어\" 이소영 의원을 비롯한 더불어민주당 2030의원들이 9일 오전 서울 여의도 국회 소통관에서 '더불어민주당 2030의원 입장문' 발표를 기자회견을 하고 있다.\n",
            "[ 2 ] 민주당 오영환·이소영·장경태·장철민·전용기 의원은 이날 오전 국회 소통관에서 기자회견을 열고 \"선거 유세 현장과 삶의 현장에서 만난 20대 30대 청년들은 민주당에 싸늘하고 무관심했고 지난 1년 동안 많은 분의 마음이 돌아섰음을 현장에서 느꼈다\"고 말했다.\n",
            "[ 3 ] 이들은 \"이번 재보궐선거를 치르게 된 원인이 우리 당 공직자의 성 비위 문제였음에도 불구하고 우리 당은 당헌·당규를 개정해 후보를 내고 피해자에 대한 제대로 된 사죄도 없었다\"며 \"당내 2차 가해를 적극적으로 막는 조처를 하지 않았다. 이 문제를 회피하고 외면할 수 있지 않을까 하는 오만함이었다\"고 비판했다.\n"
          ]
        }
      ],
      "source": [
        "rtn = summarize_test(test1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Summary'] = df['Text'].apply(lambda x: summarize_test(x))\n",
        "df"
      ],
      "metadata": {
        "id": "chRGPZy2ZJoD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b04aac73-ab91-4527-dc76-491aa1341490"
      },
      "id": "chRGPZy2ZJoD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1 ] 민주당 오영환·이소영·장경태·장철민·전용기 의원은 이날 오전 국회 소통관에서 기자회견을 열고 \"선거 유세 현장과 삶의 현장에서 만난 20대 30대 청년들은 민주당에 싸늘하고 무관심했고 지난 1년 동안 많은 분의 마음이 돌아섰음을 현장에서 느꼈다\"고 말했다.\n",
            "[ 2 ] 이들은 \"이번 재보궐선거를 치르게 된 원인이 우리 당 공직자의 성 비위 문제였음에도 불구하고 우리 당은 당헌·당규를 개정해 후보를 내고 피해자에 대한 제대로 된 사죄도 없었다\"며 \"당내 2차 가해를 적극적으로 막는 조처를 하지 않았다. 이 문제를 회피하고 외면할 수 있지 않을까 하는 오만함이었다\"고 비판했다.\n",
            "[ 3 ] \"가르치려 한 오만함, 청년과 단절 원인\" 반성 \"박원순 피해자 제대로 된 사과와 반성 이뤄지지 않았어\" 이소영 의원을 비롯한 더불어민주당 2030의원들이 9일 오전 서울 여의도 국회 소통관에서 '더불어민주당 2030의원 입장문' 발표를 기자회견을 하고 있다.\n",
            "[ 1 ] 동영상 뉴스                  '조국 사태'로 공정 가치 문제 본격적으로 불거져 인국공 사태·윤미향·박원순까지 공정 문제 지속 LH 사태로 文 정부 표방 공정 가치 또 흔들려 민주당 의원들, '조국 지키기' 첫 공개 비판 [앵커] 더불어민주당 2030 세대 의원들이 총선 참패의 원인은 민주당 내부에 있다며 반성문을 내놨습니다.\n",
            "[ 2 ] 가장 눈에 띄는 건 민주당 안에서는 금기처럼 치부되던 조국 사태에 대한 첫 반성입니다.\n",
            "[ 3 ] 결국, 그동안 민주당 지지 성향으로 분류되던 2, 30대가 등을 돌리며 선거 패배의 주요 요인으로 꼽혔습니다.\n",
            "[ 1 ] 연합뉴스     더불어민주당 초선이자 20∼30대 의원인 오영환·이소영·장경태·장철민·전용기 의원 5명은 9일 입장문을 내 “민주당 참패 원인은 저희들을 포함한 민주당의 착각과 판에 있었음을 자인한다”고 밝혔다.\n",
            "[ 2 ] 이들은 국회 소통관에서 입장문을 발표하고 “이번 재보궐 선거를 치르게 된 원인이 우리 당 공직자의 성 비위 문제였음에도 불구하고 당은 당헌, 당규를 개정해 후보를 내고 피해자에 대한 제대로 된 사죄도 없었으며, 당내 2차 가해를 적극적으로 막는 조치를 취하지 않았다”며 “이 문제를 회피하고 외면할 수 있지 않을까 하는 오만함이었다”고 인정했다.\n",
            "[ 3 ] 그동안 민주당에서 초선 의원들이 당내 현안에 비판적인 입장을 밝힌 것은 이번이 처음으로, 패배 뒤 뒤늦은 반성이라는 지적도 나온다.\n",
            "[ 1 ] 동영상 뉴스                  [앵커] 이번엔 국민의힘 상황실로 가보겠습니다.\n",
            "[ 2 ] 당 지도부는 그전까진 당사에 마련된 스튜디오에서 유튜브 라이브 방송을 통해 유권자들의 투표 참여와 지지를 호소한다는 계획입니다.\n",
            "[ 3 ] 국민의힘은 현재 투표율이 지난 대선보다 높게 나오고 있는데에 한편으론 안도하면서도, 다른 한편으론 아직은 부족하다며 상황을 예의주시하고 있습니다.\n",
            "[ 1 ] 방송 3사 출구조사를 통해 분석해보니 2030 젊은 층 유권자는 남녀 성별에 따라 표심이 확연하게 갈렸습니다.\n",
            "[ 2 ] 이런 20, 30대  경향에 대해, 이재명 캠프가 막바지 젊은 층 여성 결집을 유도했고 남성 표를 의식한 윤석열 캠프 전략이 여성들에게 역으로 작용했을 수 있단 분석이 나왔습니다.\n",
            "[ 3 ] [앵커]  이번 선거 또 하나 관심은 MZ 세대라고 불리는 젊은 층 표심이 어디로 향할지였죠.\n",
            "[ 1 ] 만 18세 유권자 20명 ‘이런 대통령을 원한다’ 경기 군포 수리고 3학년 김윤산 군은 4일 하굣길에 사전투표소를 찾아 투표했다.\n",
            "[ 2 ] 동아일보는 이번 대선에서 처음 대통령을 뽑는 만 18세 유권자 20명을 인터뷰해 어떤 대통령을 원하는지 물었다.\n",
            "[ 3 ] 3·9 제20대 대통령선거는 투표 연령이 2020년 만 18세로 낮춰진 뒤 이뤄지는 첫 대선이다.\n",
            "[ 1 ] 버거킹을 거쳐 맥도날드까지 6년을 일했다.\n",
            "[ 2 ] [한겨레21] 내 곁에 산재 반지하 전세보증금 7천만원 피해 34살 연극배우의 꿈 꺾이지 않길 “병원 청소와 빌딩 청소 사이 시간 연기 연습이라도 하게 남겨뒀죠”\n",
            "[ 3 ] 서른네 살 연극배우 강시내(가명)의 서울 생활 시작이었다.\n",
            "[ 1 ] [국토부 \"1%대 긴급 저리대출·LH 임시거처 등 제공\" 임차인 \"전세금 전액 받을 길 없어지원책 불충분\"] '빌라왕' 사태 등 전세사기 피해자 절반에 달하는 보증보험 미가입자에 대한 구제안이 마련됐다.\n",
            "[ 2 ] 경매로 인해 머물 곳이 없어진 피해임차인들에게는 신규임차를 위한 1%대 긴급저리대출과 긴급거처 등이 제공된다.\n",
            "[ 3 ] 이원재 국토교통부 제1차관은 10일 서울 여의도 전경련회관에서 열린 '전세보증금 피해 임차인 설명회'에서 \"보증보험 미가입자에 대해서는 센터를 통한 법률 상담을 포함해 여러 가지 금융지원을 마련해 추진 중\"이라고 밝혔다.\n",
            "[ 1 ] MBC는 2015년부터 2018년 사이 빌라를 집중적으로 매입한 뒤 보증 사고를 낸 이른바 '1세대 빌라왕' 10명을 추적했습니다\n",
            "[ 2 ] 보증사고를 가장 많이 낸 10명을 추려봤는데 처벌받은 사람은 단 한 명 뿐이었습니다.\n",
            "[ 3 ] [뉴스투데이] ◀ 앵커 ▶ 잇따라 터져나오는 빌라왕들의 전세사기.\n",
            "[ 1 ] 두달새 3명째 청년들 앗아간 전세사기 인천 31세 피해여성 숨진채 발견 “다신 이런 일 없었으면” 유서 남겨 정부 구제대책 별다른 도움 안돼 집 경매 넘어간 피해자들 벼랑끝 수도권 일대에 주택 2700여 채를 보유한 이른바 ‘미추홀구 건축왕’ 남모 씨(61)에게 전세 사기를 당한 피해자가 17일 새벽 숨진 채 발견됐다.\n",
            "[ 2 ] ‘건축왕’으로부터 전세 사기를 당한 20, 30대 청년이 극단적 선택을 한 건 2월 말과 이달 14일에 이어 세 번째여서 추가 희생을 막기 위한 대책이 시급하다는 목소리가 나온다.\n",
            "[ 3 ] 인천 미추홀경찰서 등에 따르면 17일 오전 1시 22분경 박모 씨(31·여)가 미추홀구의 한 아파트 자택에서 의식을 잃고 쓰러진 채 남자친구에 의해 발견됐다.\n",
            "[ 1 ] 무자본·갭투자 ‘광주 빌라왕’ ‘미추홀구 건축왕’과 동일수법 ‘중대 민생범죄 변호’ 논란 전세사기 피해가 ‘사회적 재난’ 수준으로 확산하고 있는 가운데, 양부남(62·사법연수원 22기·사진) 더불어민주당 법률위원장이 올해 초까지 광주·전남 지역에서 1000억 원대 전세사기를 벌인 ‘광주 빌라왕’의 변호를 맡았던 것으로 확인됐다.\n",
            "[ 2 ] 19일 법조계에 따르면, 양 위원장은 지난해 10월 전세사기 혐의로 붙잡힌 정모 씨(구속기소)에 대한 경찰 조사가 시작되자 변호인으로 선임됐다.\n",
            "[ 3 ] 전세사기 피해자들의 피눈물 섞인 절규가 이어지는 상황에서 지난해 9월 민주당 법률 사무를 총괄하는 법률위원장을 맡은 직후 중대 민생범죄 피의자 변호를 맡아 논란이 커질 것으로 보인다.\n",
            "[ 1 ] [전세사기 피해] 인천 미추홀 피해대책위 실태조사 “12개 단지는 사실상 통째 경매로 보증금 못받아 거리에 나앉게 돼” 정부 “피해 주택 경매절차 중단” 수도권 일대 주택 2700여 채를 보유한 인천 ‘미추홀구 건축왕’ 남모 씨(61)의 전세사기로 청년 3명이 목숨을 잃은 가운데 사실상 한 개 동 전체가 경매에 넘어간 집합건물(아파트, 오피스텔, 빌라)이 미추홀구에만 12곳에 달하는 것으로 나타났다.\n",
            "[ 2 ] 전세보증금을 돌려받지 못한 피해자들이 경매로 거리에 나앉게 됐다는 지적이 나오자 정부는 뒤늦게 경매 진행 중단 방침을 밝혔다.\n",
            "[ 3 ] 피해자 단체는 건축왕 피해자 거주 주택 중 2000채 이상이 경매에 넘어간 것으로 추정하고 있다.\n",
            "[ 1 ] 황 대표는 황급히 “법리적 차원의 일반적인 얘기”라며 “가해자 및 참여자 모두 무관용 원칙으로 철저한 수사와 단호한 처벌이 필요하다는 확고한 입장이다”라고 해명했지만 관련한 비판은 계속되고 있다.\n",
            "[ 2 ] n번방 사건을 계기로 성범죄 처벌 수준을 확대해야 한다는 목소리가 높아지고 있고, 수사당국이 n번방 가담자 전원에 엄정 수사를 벌인다는 방침을 내세운 상황에서 적절하지 않은 발언이었다는 것이다.\n",
            "[ 3 ] 뉴시스     미래통합당 황교안 대표가 지난 1일 미성년자 등을 협박해 성착취 영상을 제작·공유한 ‘텔레그램 n번방’에 대해 “호기심으로 방에 들어왔다 그만둔 사람들에 대해서 판단이 다를 수 있다”고 말해 논란이 일었다.\n",
            "[ 1 ] [한국경제TV 이휘경 기자] 범여권은 1일 미래통합당 황교안 대표가 텔레그램 n번방에 '호기심'으로 들어간 사람은 신상 공개 여부를 다르게 판단해야 한다는 취지로 말한 것에 대해 성범죄 가해자를 봐주자는 주장이라며 일제히 비난했다.\n",
            "[ 2 ] 정의당 심상정 대표도 보도자료에서 \"n번방 사건의 참여자들은 단순히 '시청'한 것이 아니라, 피해자에 대한 폭력을 함께 모의하고 부추기는 적극적인 가담자\"라며 \"황 대표의 발언은 매우 문제적이다. 당장 피해자와 국민 앞에 사과하기 바란다\"고 요구했다.\n",
            "[ 3 ] 더불어민주당 강훈식 수석대변인은 이날 브리핑에서 \"n번방 사건에 대한 황 대표의 몰지각한 '호기심' 발언이 국민들 분노를 자아내고 있다\"며 \"황교안 대표는 n번방 가입을 단순한 호기심으로 치부하고 끔찍한 범죄 가해자에게 관용을 베풀고 싶은 것인가\"라고 물었다.\n",
            "[ 1 ] \"초대받고 암호화폐 입장료 내는 구조단순 호기심으로 들어갈 수 없어\" 방송기자클럽 토론 참석한 황교안(서울=연합뉴스) 진성철 기자 = 미래통합당 황교안 대표가 1일 서울 양천구 목동동로 방송회관에서 열린 방송기자클럽 초청 토론회에서 발언하고 있다.\n",
            "[ 2 ] 더불어민주당 강훈식 수석대변인은 이날 브리핑에서 \"n번방 사건에 대한 황 대표의 몰지각한 '호기심' 발언이 국민들 분노를 자아내고 있다\"며 \"황교안 대표는 n번방 가입을 단순한 호기심으로 치부하고 끔찍한 범죄 가해자에게 관용을 베풀고 싶은 것인가\"라고 물었다.\n",
            "[ 3 ] 열린민주당의 여성 비례대표 후보들도 성명에서 \"성범죄와 청소년 문제에 대한 황 대표의 인식이 얼마나 안이한지 분노마저 인다\"며 \"도저히 공당 대표의 발언이라고는 믿을 수 없는 일\"이라고 비판했다.\n",
            "[ 1 ] 한동훈 법무부 장관이 신당역 스토킹 살인 범죄와 관련, 검찰에 '스토킹 범죄 엄정 대응'을 지시했다.\n",
            "[ 2 ] 법무부는 피해자와 합의 등으로 가해자가 처벌을 피할 수 있는 현행 스토킹범죄처벌법의 허점이 크다고 보고 정부 입법을 통해 개정을 추진하기로 했다. ━\n",
            "[ 3 ] \"지난해 10월부터 '스토킹범죄 처벌법'이 시행 중이지만, 스토킹과 보복범죄가 끊이지 않고 있다\"고 하면서다.\n",
            "[ 1 ] 일회용 승차권으로 '신당역'까지 이동 흉기 사전에 준비철저한 '계획범죄' [이데일리 권혜미 기자] 서울 지하철 2호선 신당역에서 여성 역무원을 살해한 남성은 스토킹하던 여성에게 ‘보복살인’을 한 철저한 계획범죄로 밝혀졌다.\n",
            "[ 2 ] 15일 경찰과 서울교통공사에 따르면 서울교통공사 직원인 피의자 전모(31)씨는 지난 14일 밤 피해자 A씨가 근무하고 있는 신당역에 모습을 드러냈다.\n",
            "[ 3 ] 그리고 오후 8시 56분, A씨가 순찰을 위해 여자화장실로 들어가는 것을 보고 바로 뒤따라 들어가 흉기를 휘둘렀다.\n",
            "[ 1 ] 한동훈 법무부 장관은 15일 ‘스토킹 살인 사건’이 일어난 서울 지하철 2호선 신당역을 찾아 “국가가 피해자를 지키지 못했다”고 말했다.\n",
            "[ 2 ] B씨는 신당역 여자화장실을 순찰하던 A씨를 쫓아가 범행을 저지른 것으로 드러났다.\n",
            "[ 3 ] 한 장관은 현장에서 기자와 만나 “유족들의 슬픔이 가늠조차 되지 않는다.\n",
            "[ 1 ] \"환기 잘 되는 시설엔 방역패스 필요없는 환기 등급제 적용 [속보]윤석열 \"비과학적 방역패스 철회, 아동청소년 강제적 백신접종 반대\" ◇사진=윤석열 SNS 캡처 윤석열 국민의힘 대선후보는 11일 오후 자신의 SNS에 \"비과학적 방역패스 철회, 9시 영업제한 철회, 아동청소년 강제적 백신접종 반대\"를 공약으로 내세웠다. 윤 후보는 지난 7일 '여성가족부 폐지'라는 일곱 글자를 남기며 정치권에 파장을 일으킨바 있다. 윤 후보는 최근 선대위 내 2030 자문그룹의 조언을 반영해 앞선 공약보다 더 진전된 방향으로 입장을 선회한 것으로 알려졌다. 이에 앞서 윤 후보는 이날 오후 국회에서 토론회를 열고 현 정부의 방역 대책이 \"비과학적이고 무리한 측면이 많다\"며 \"만원 버스와 지하철에는 방역 패스를 적용하지 않으면서 마트, 백화점에는 적용한다는 게 이해가 가지 않는다\"고 말했다. 이어 중구 대한간호협회를 찾아 간호사들과 간담회에서 \"2년 넘게 지속되는 코로나 팬데믹 속에서 우리 간호사 분들의 희생과 헌신을 이루 말할 수 없다\"며 \"국민의 한 사람으로서 깊이 감사드린다\"고 말했다. 이어 \"간호 인력 부족은 하루이틀의 문제가 아니다\"라며 \"코로나 사태 장기화로 많은 간호사들이 번아웃으로 현장을 떠나는 실정이라며 업무 환경 개선이나 업계 숙원인 간호법 제정에 관심을 갖겠다\"고 했다. 또한 윤 후보는 환기 등급제를 통해 환기가 잘 되는 시설에 대해서는 방역 패스를 적용하지 않는 정책이 필요하다는 주장을 폈다. 윤 후보는 \"환기 정도에 따라 감염 전파에 차이가 있다는 것은 질병관리청 자료로도 확인된 사실\"이라며 \"시설별로 체계적인 환기 등급제를 적용하는 방안을 검토해야 한다\"고 밝혔다. 이어 \"국공립 기관부터 우선 적용하고, 민간 시설에 대해서는 중앙정부와 지방자치단체가 기준을 마련할 필요가 있다\"고 말했다. 윤 후보는 \"실내 공간이 클수록 바이러스 노출 확률이 줄어드는 만큼 공간의 크기도 반영돼야 한다\"며 \"바닥 면적뿐 아니라 천장 높이까지 종합적인 고려가 필요하다\"고 주장했다. 이어 \"요양병원 등 고위험 시설이나 소상공인 업장의 경우 환기 수준 자체를 높일 수 있도록 실내 바이러스 저감 장치 설치 등에 대한 정부의 별도 지원이 필요하다\"고 강조했다. 윤 후보는 현 정부의 방역 대책이 비과학적이고 무리한 측면이 많다며 \"만원 버스와 지하철에는 방역 패스를 적용하지 않으면서 마트, 백화점에는 적용한다는 게 이해가 가지 않는다\"고 말했다. 선대본부 산하 코로나위기대응위원회 위원장을 맡은 정기석 전 질병관리본부장도 \"환기 지침만 내놓고 정책에 반영하지 않고 있다\"며 \"환기만 잘해도 감염률이 30∼50％ 준다\"고 설명했다.\n",
            "[ 1 ] “간호사 관련 법률, 1951년 제정된 국민의료법 틀에 갇혀”         이재명 더불어민주당 대선 후보가 11일 “전 국민의 보편적 건강 보장을 위한 간호법 제정을 적극 추진하겠다”고 했다.\n",
            "[ 2 ] 이런 가운데 이 후보가 간호계의 손을 들어준 셈이다.\n",
            "[ 3 ] 간호법 제정은 간호사의 업무 범위에 대한 해석을 두고 간호계와 의사단체간의 의견이 충돌하고 있는 사안이다.\n",
            "[ 1 ] 간호사의업무 범위에 대한해석을두고간호 계와 의사단체간의견이 충돌하 고있는가운데, 두후보 모두 간호계 의손 을들어준 셈이다.\n",
            "[ 2 ] 간호계-의사단체간갈등국면서간호 계손들어줘..\n",
            "[ 3 ] 사진=뉴스1[ 파이낸셜 뉴스]이재명더불어 민주당 대선후보와윤석열국민의힘대선후보가11 일동시에'간호법' 제정추진에목소리를냈다.\n",
            "[ 1 ] 대한간호협회는 17일 오전 기자회견을 열고 “우리 간호사는 준법투쟁을 전개할 것”이라며 “임상병리사 등 다른 보건의료직능의 면허업무에 대한 의사의 지시를 거부할 것”이라고 밝혔다.\n",
            "[ 2 ] 또 “오늘부터 한 달 간 전국 간호사의 면허증을 모아 보건복지부로 반납할 것이며 면허 반납을 하는 그날 간호사는 광화문에 집결해 허위사실로 부당하게 공권력을 행사한 보건복지부 장차관을 고발하고 파면을 요구할 것”이라고 말했다. 이어 “5월19일 광화문에서 ‘간호법 거부권 규탄 및 부패정치 척결을 위한 범국민 규탄 대회’를 개최하고 간호사는 19일 연차 신청을 통해 규탄 집회에 참석할 것”이라고 밝혔다.\n",
            "[ 1 ] 윤석열 대통령이 16일 오전 대통령실에서 진행한 국무회의에서 간호법 제정안에 대해 법률안 재의요구권(거부권)을 행사하자 더불어민주당의 박광온 원내대표 등이 입장 철회를 요구한 가운데, 이재명 당 대표도 \"대통령은 공약 파기 이유를 국민이 납득할 수 있도록 설명하고 공약 파기에 대해서 사죄해야 한다\"며 \"헛공약, 공약 팍는 민주주의를 파기하는 민주주의에 대한 도전\"이라고 꼬집었다.\n",
            "[ 2 ] 이재명 더불어민주당 대표가 윤석열 대통령의 간호법 거부권 행사를 두고 즉각 비판했다.\n",
            "[ 3 ] 이재명 대표는 이날 오후 경기도 안성시 죽산면에서 청년농업인들과 간담회를 마친 후 언론에 \"민주주의 국가에서 정치인들은 국민에게 약속을 하고 권한을 위임받는다. 주권자인 국민은 정치인의 약속을 믿고 주권을 위임한다. 그래서 신뢰는 민주주의를 떠받치는 가장 중요한 토대\"라고 강조했다. 이어 \"모든 국민이 아는 것처럼 간호법 제정은 윤석열 대통령의 대선 후보 당시 공약이었다. 그 공약에 따라 여야는 상임위에서 이 간호법안을 처리했다. 그런데 대통령은 지킬 수 없는 객관적 사정이 전혀 없는 데도 공약을 어기고, 국회가 처리한 간호법에 거부권을 행사했다\"고 설명했다.\n",
            "[ 1 ] 대통령실 \"간호계 요구 귀 막고 있지 않아\" 거부권 추가 행사 관측엔 \"특수성 고려해 판단\" 윤석열 대통령이 16일 의료계 직역 간 갈등이 첨예한 `간호법 제정안`에 대해 \"국민 건강은 그 어느 것과도 바꿀 수 없다\"며 재의요구권(거부권)을 행사했다.\n",
            "[ 2 ] 지난 4월 `양곡관리법 개정안`에 이어 윤석열 정부 출범 이후 두 번째 거부권 행사 사례다.\n",
            "[ 3 ] 윤 대통령은 지난 대선 후보 시절 간호법 제정안을 추진하겠다는 취지의 공언을 한 바 있어 `공약 파기` 지적이 나온다.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date Publisher  Comments                                       Title  \\\n",
              "0  2021-04-09       뉴스1      1868  與 2030 의원들 \"조국 관련, 사과할 용의 있어…착각·오판 자인\"(종합)   \n",
              "1  2021-04-09       YTN       684         민주당 2030 의원들의 반성문...'조국 사태' 첫 공개 반성   \n",
              "2  2021-04-09       한겨레       392       민주당 2030 의원들 “야당·언론·청년 때문에 참패? 동의 못해”   \n",
              "3  2022-03-09      JTBC       963            윤석열 \"투표율, 기대 미치지 못해\"…여러차례 독려 메시지   \n",
              "4  2022-03-10       KBS       824             젊은 층 표심은? ‘이대남’은 윤석열·‘이대녀’는 이재명   \n",
              "5  2022-03-09      동아일보       681      “첫 투표, 진정한 국민 된 기분… 집값-일자리 해결할 대통령 원해”   \n",
              "6  2023-01-12       한겨레       241           ‘빌라왕’ 문자 받은 배우…햄버거 알바하던 손이 덜덜 떨려도   \n",
              "7  2023-01-11     머니투데이       155                   빌라왕 전세사기 피해…\"보증 미가입자도 구제\"   \n",
              "8  2023-01-12       MBC       146                 '479채 빌라왕' 전재산 1천만 원‥10명 추적   \n",
              "9  2023-04-18      동아일보      1061            “난 의지할 부모도 없다” 유서…쓰레기봉투엔 정신과 약봉지   \n",
              "10 2023-04-19      문화일보       890     [단독] 양부남 민주당 법률위원장 ‘1000억 전세 사기범’ 변호했었다   \n",
              "11 2023-04-19      동아일보       828                      “전세사기 주택 2083채 경매 넘어가”   \n",
              "12 2020-04-02      세계일보      1396        황교안 ‘n번방 호기심’ 발언에 “사이코패스”, “일벌백계” 비판   \n",
              "13 2020-04-01    한국경제TV       616             \"n번방, 호기심에 들어갔다면\"…황교안 발언 '집중포화'   \n",
              "14 2020-04-01      연합뉴스       586    황교안 'n번방 호기심' 발언 비난 쏟아져…\"범죄자 봐주자는 것\"(종합)   \n",
              "15 2022-09-16      중앙일보      1683          신당역 \"국가가 못지켰다\"던 한동훈 \"스토킹, 합의해도 처벌\"   \n",
              "16 2022-09-16      이데일리      1079           '신당역' 역무원 살해범, 위생모 쓴 이유는…'그날의 행적'   \n",
              "17 2022-09-15      조선일보       903      한동훈, 스토킹 살인 현장 예고없이 방문… “국가가 지켜주지 못했다”   \n",
              "18 2022-01-11      강원일보       365       윤석열 \"비과학적 방역패스 철회, 아동청소년 강제적 백신접종 반대\"   \n",
              "19 2022-01-11      조선비즈        90           간호계·의료계 충돌 중인데…이재명 “간호법 제정 적극 추진”   \n",
              "20 2022-01-11    파이낸셜뉴스        57              이재명·윤석열, 같은 날 \"간호법 제정 추진\" 한목소리   \n",
              "21 2023-05-17      경향신문       693      [속보]간호협회 “오늘부터 대리처방·수술 거부···면허증 반납하겠다”   \n",
              "22 2023-05-16      매일신문       603  [속보] 이재명 \"尹 간호법 거부권 행사는 민주주의 도전, 헛공약 사죄하라\"   \n",
              "23 2023-05-17       더팩트       480       尹대통령, `공약`한 간호법도 거부권 행사…간호사단체 \"약속 파기\"   \n",
              "\n",
              "                                                 Text           Topic  \\\n",
              "0   \"가르치려 한 오만함, 청년과 단절 원인\" 반성 \"박원순 피해자 제대로 된 사과와 ...     youth_peak1   \n",
              "1   동영상 뉴스                  '조국 사태'로 공정 가치 문제 본격적으...     youth_peak1   \n",
              "2   오영환·이소영·장경태·장철민·전용기 등 입장문 발표 더불어민주당 전용기, 오영환, ...     youth_peak1   \n",
              "3   동영상 뉴스                  [앵커] 이번엔 국민의힘 상황실로 가보겠...     youth_peak2   \n",
              "4   [앵커]  이번 선거 또 하나 관심은 MZ 세대라고 불리는 젊은 층 표심이 어디로 ...     youth_peak2   \n",
              "5   만 18세 유권자 20명 ‘이런 대통령을 원한다’ 경기 군포 수리고 3학년 김윤산 ...     youth_peak2   \n",
              "6   [한겨레21] 내 곁에 산재 반지하 전세보증금 7천만원 피해 34살 연극배우의 꿈 ...      rent_peak1   \n",
              "7   [국토부 \"1%대 긴급 저리대출·LH 임시거처 등 제공\" 임차인 \"전세금 전액 받을...      rent_peak1   \n",
              "8   [뉴스투데이] ◀ 앵커 ▶ 잇따라 터져나오는 빌라왕들의 전세사기. 같은 수법의 사기...      rent_peak1   \n",
              "9   두달새 3명째 청년들 앗아간 전세사기 인천 31세 피해여성 숨진채 발견 “다신 이런...      rent_peak2   \n",
              "10  무자본·갭투자 ‘광주 빌라왕’ ‘미추홀구 건축왕’과 동일수법 ‘중대 민생범죄 변호’...      rent_peak2   \n",
              "11  [전세사기 피해] 인천 미추홀 피해대책위 실태조사 “12개 단지는 사실상 통째 경매...      rent_peak2   \n",
              "12  미래통합당 황교안 대표가 1일 서울 양천구 목동동로 방송회관에서 열린 방송기자클럽 ...  stalking_peak1   \n",
              "13  [한국경제TV 이휘경 기자] 범여권은 1일 미래통합당 황교안 대표가 텔레그램 n번방...  stalking_peak1   \n",
              "14  \"초대받고 암호화폐 입장료 내는 구조단순 호기심으로 들어갈 수 없어\" 방송기자클럽 ...  stalking_peak1   \n",
              "15  한동훈 법무부 장관이 신당역 스토킹 살인 범죄와 관련, 검찰에 '스토킹 범죄 엄정 ...  stalking_peak2   \n",
              "16  일회용 승차권으로 '신당역'까지 이동 흉기 사전에 준비철저한 '계획범죄' [이데일리...  stalking_peak2   \n",
              "17  한동훈 법무부 장관은 15일 ‘스토킹 살인 사건’이 일어난 서울 지하철 2호선 신당...  stalking_peak2   \n",
              "18  \"환기 잘 되는 시설엔 방역패스 필요없는 환기 등급제 적용 [속보]윤석열 \"비과학적...     nurse_peak1   \n",
              "19  “간호사 관련 법률, 1951년 제정된 국민의료법 틀에 갇혀”         이재명...     nurse_peak1   \n",
              "20  간호계-의사단체간 갈등 국면서 간호계 손 들어줘..국회서 처리 주목   국회사진기자...     nurse_peak1   \n",
              "21  대한간호협회는 17일 오전 기자회견을 열고 “우리 간호사는 준법투쟁을 전개할 것”이...     nurse_peak2   \n",
              "22  이재명 더불어민주당 대표가 윤석열 대통령의 간호법 거부권 행사를 두고 즉각 비판했다...     nurse_peak2   \n",
              "23  대통령실 \"간호계 요구 귀 막고 있지 않아\" 거부권 추가 행사 관측엔 \"특수성 고려...     nurse_peak2   \n",
              "\n",
              "                                              Summary  \n",
              "0   [민주당 오영환·이소영·장경태·장철민·전용기 의원은 이날 오전 국회 소통관에서 기자...  \n",
              "1   [동영상 뉴스                  '조국 사태'로 공정 가치 문제 본격적...  \n",
              "2   [연합뉴스     더불어민주당 초선이자 20∼30대 의원인 오영환·이소영·장경태·장...  \n",
              "3   [동영상 뉴스                  [앵커] 이번엔 국민의힘 상황실로 가보...  \n",
              "4   [방송 3사 출구조사를 통해 분석해보니 2030 젊은 층 유권자는 남녀 성별에 따라...  \n",
              "5   [만 18세 유권자 20명 ‘이런 대통령을 원한다’ 경기 군포 수리고 3학년 김윤산...  \n",
              "6   [버거킹을 거쳐 맥도날드까지 6년을 일했다., [한겨레21] 내 곁에 산재 반지하 ...  \n",
              "7   [[국토부 \"1%대 긴급 저리대출·LH 임시거처 등 제공\" 임차인 \"전세금 전액 받...  \n",
              "8   [MBC는 2015년부터 2018년 사이 빌라를 집중적으로 매입한 뒤 보증 사고를 ...  \n",
              "9   [두달새 3명째 청년들 앗아간 전세사기 인천 31세 피해여성 숨진채 발견 “다신 이...  \n",
              "10  [무자본·갭투자 ‘광주 빌라왕’ ‘미추홀구 건축왕’과 동일수법 ‘중대 민생범죄 변호...  \n",
              "11  [[전세사기 피해] 인천 미추홀 피해대책위 실태조사 “12개 단지는 사실상 통째 경...  \n",
              "12  [황 대표는 황급히 “법리적 차원의 일반적인 얘기”라며 “가해자 및 참여자 모두 무...  \n",
              "13  [[한국경제TV 이휘경 기자] 범여권은 1일 미래통합당 황교안 대표가 텔레그램 n번...  \n",
              "14  [\"초대받고 암호화폐 입장료 내는 구조단순 호기심으로 들어갈 수 없어\" 방송기자클럽...  \n",
              "15  [한동훈 법무부 장관이 신당역 스토킹 살인 범죄와 관련, 검찰에 '스토킹 범죄 엄정...  \n",
              "16  [일회용 승차권으로 '신당역'까지 이동 흉기 사전에 준비철저한 '계획범죄' [이데일...  \n",
              "17  [한동훈 법무부 장관은 15일 ‘스토킹 살인 사건’이 일어난 서울 지하철 2호선 신...  \n",
              "18  [\"환기 잘 되는 시설엔 방역패스 필요없는 환기 등급제 적용 [속보]윤석열 \"비과학...  \n",
              "19  [“간호사 관련 법률, 1951년 제정된 국민의료법 틀에 갇혀”         이재...  \n",
              "20  [간호사의업무 범위에 대한해석을두고간호 계와 의사단체간의견이 충돌하 고있는가운데, ...  \n",
              "21  [대한간호협회는 17일 오전 기자회견을 열고 “우리 간호사는 준법투쟁을 전개할 것”...  \n",
              "22  [윤석열 대통령이 16일 오전 대통령실에서 진행한 국무회의에서 간호법 제정안에 대해...  \n",
              "23  [대통령실 \"간호계 요구 귀 막고 있지 않아\" 거부권 추가 행사 관측엔 \"특수성 고...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-645bf8a6-4140-42c8-875f-65952e941cd5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Title</th>\n",
              "      <th>Text</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>뉴스1</td>\n",
              "      <td>1868</td>\n",
              "      <td>與 2030 의원들 \"조국 관련, 사과할 용의 있어…착각·오판 자인\"(종합)</td>\n",
              "      <td>\"가르치려 한 오만함, 청년과 단절 원인\" 반성 \"박원순 피해자 제대로 된 사과와 ...</td>\n",
              "      <td>youth_peak1</td>\n",
              "      <td>[민주당 오영환·이소영·장경태·장철민·전용기 의원은 이날 오전 국회 소통관에서 기자...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>YTN</td>\n",
              "      <td>684</td>\n",
              "      <td>민주당 2030 의원들의 반성문...'조국 사태' 첫 공개 반성</td>\n",
              "      <td>동영상 뉴스                  '조국 사태'로 공정 가치 문제 본격적으...</td>\n",
              "      <td>youth_peak1</td>\n",
              "      <td>[동영상 뉴스                  '조국 사태'로 공정 가치 문제 본격적...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>392</td>\n",
              "      <td>민주당 2030 의원들 “야당·언론·청년 때문에 참패? 동의 못해”</td>\n",
              "      <td>오영환·이소영·장경태·장철민·전용기 등 입장문 발표 더불어민주당 전용기, 오영환, ...</td>\n",
              "      <td>youth_peak1</td>\n",
              "      <td>[연합뉴스     더불어민주당 초선이자 20∼30대 의원인 오영환·이소영·장경태·장...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-03-09</td>\n",
              "      <td>JTBC</td>\n",
              "      <td>963</td>\n",
              "      <td>윤석열 \"투표율, 기대 미치지 못해\"…여러차례 독려 메시지</td>\n",
              "      <td>동영상 뉴스                  [앵커] 이번엔 국민의힘 상황실로 가보겠...</td>\n",
              "      <td>youth_peak2</td>\n",
              "      <td>[동영상 뉴스                  [앵커] 이번엔 국민의힘 상황실로 가보...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-03-10</td>\n",
              "      <td>KBS</td>\n",
              "      <td>824</td>\n",
              "      <td>젊은 층 표심은? ‘이대남’은 윤석열·‘이대녀’는 이재명</td>\n",
              "      <td>[앵커]  이번 선거 또 하나 관심은 MZ 세대라고 불리는 젊은 층 표심이 어디로 ...</td>\n",
              "      <td>youth_peak2</td>\n",
              "      <td>[방송 3사 출구조사를 통해 분석해보니 2030 젊은 층 유권자는 남녀 성별에 따라...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-03-09</td>\n",
              "      <td>동아일보</td>\n",
              "      <td>681</td>\n",
              "      <td>“첫 투표, 진정한 국민 된 기분… 집값-일자리 해결할 대통령 원해”</td>\n",
              "      <td>만 18세 유권자 20명 ‘이런 대통령을 원한다’ 경기 군포 수리고 3학년 김윤산 ...</td>\n",
              "      <td>youth_peak2</td>\n",
              "      <td>[만 18세 유권자 20명 ‘이런 대통령을 원한다’ 경기 군포 수리고 3학년 김윤산...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2023-01-12</td>\n",
              "      <td>한겨레</td>\n",
              "      <td>241</td>\n",
              "      <td>‘빌라왕’ 문자 받은 배우…햄버거 알바하던 손이 덜덜 떨려도</td>\n",
              "      <td>[한겨레21] 내 곁에 산재 반지하 전세보증금 7천만원 피해 34살 연극배우의 꿈 ...</td>\n",
              "      <td>rent_peak1</td>\n",
              "      <td>[버거킹을 거쳐 맥도날드까지 6년을 일했다., [한겨레21] 내 곁에 산재 반지하 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2023-01-11</td>\n",
              "      <td>머니투데이</td>\n",
              "      <td>155</td>\n",
              "      <td>빌라왕 전세사기 피해…\"보증 미가입자도 구제\"</td>\n",
              "      <td>[국토부 \"1%대 긴급 저리대출·LH 임시거처 등 제공\" 임차인 \"전세금 전액 받을...</td>\n",
              "      <td>rent_peak1</td>\n",
              "      <td>[[국토부 \"1%대 긴급 저리대출·LH 임시거처 등 제공\" 임차인 \"전세금 전액 받...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2023-01-12</td>\n",
              "      <td>MBC</td>\n",
              "      <td>146</td>\n",
              "      <td>'479채 빌라왕' 전재산 1천만 원‥10명 추적</td>\n",
              "      <td>[뉴스투데이] ◀ 앵커 ▶ 잇따라 터져나오는 빌라왕들의 전세사기. 같은 수법의 사기...</td>\n",
              "      <td>rent_peak1</td>\n",
              "      <td>[MBC는 2015년부터 2018년 사이 빌라를 집중적으로 매입한 뒤 보증 사고를 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2023-04-18</td>\n",
              "      <td>동아일보</td>\n",
              "      <td>1061</td>\n",
              "      <td>“난 의지할 부모도 없다” 유서…쓰레기봉투엔 정신과 약봉지</td>\n",
              "      <td>두달새 3명째 청년들 앗아간 전세사기 인천 31세 피해여성 숨진채 발견 “다신 이런...</td>\n",
              "      <td>rent_peak2</td>\n",
              "      <td>[두달새 3명째 청년들 앗아간 전세사기 인천 31세 피해여성 숨진채 발견 “다신 이...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2023-04-19</td>\n",
              "      <td>문화일보</td>\n",
              "      <td>890</td>\n",
              "      <td>[단독] 양부남 민주당 법률위원장 ‘1000억 전세 사기범’ 변호했었다</td>\n",
              "      <td>무자본·갭투자 ‘광주 빌라왕’ ‘미추홀구 건축왕’과 동일수법 ‘중대 민생범죄 변호’...</td>\n",
              "      <td>rent_peak2</td>\n",
              "      <td>[무자본·갭투자 ‘광주 빌라왕’ ‘미추홀구 건축왕’과 동일수법 ‘중대 민생범죄 변호...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2023-04-19</td>\n",
              "      <td>동아일보</td>\n",
              "      <td>828</td>\n",
              "      <td>“전세사기 주택 2083채 경매 넘어가”</td>\n",
              "      <td>[전세사기 피해] 인천 미추홀 피해대책위 실태조사 “12개 단지는 사실상 통째 경매...</td>\n",
              "      <td>rent_peak2</td>\n",
              "      <td>[[전세사기 피해] 인천 미추홀 피해대책위 실태조사 “12개 단지는 사실상 통째 경...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2020-04-02</td>\n",
              "      <td>세계일보</td>\n",
              "      <td>1396</td>\n",
              "      <td>황교안 ‘n번방 호기심’ 발언에 “사이코패스”, “일벌백계” 비판</td>\n",
              "      <td>미래통합당 황교안 대표가 1일 서울 양천구 목동동로 방송회관에서 열린 방송기자클럽 ...</td>\n",
              "      <td>stalking_peak1</td>\n",
              "      <td>[황 대표는 황급히 “법리적 차원의 일반적인 얘기”라며 “가해자 및 참여자 모두 무...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2020-04-01</td>\n",
              "      <td>한국경제TV</td>\n",
              "      <td>616</td>\n",
              "      <td>\"n번방, 호기심에 들어갔다면\"…황교안 발언 '집중포화'</td>\n",
              "      <td>[한국경제TV 이휘경 기자] 범여권은 1일 미래통합당 황교안 대표가 텔레그램 n번방...</td>\n",
              "      <td>stalking_peak1</td>\n",
              "      <td>[[한국경제TV 이휘경 기자] 범여권은 1일 미래통합당 황교안 대표가 텔레그램 n번...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2020-04-01</td>\n",
              "      <td>연합뉴스</td>\n",
              "      <td>586</td>\n",
              "      <td>황교안 'n번방 호기심' 발언 비난 쏟아져…\"범죄자 봐주자는 것\"(종합)</td>\n",
              "      <td>\"초대받고 암호화폐 입장료 내는 구조단순 호기심으로 들어갈 수 없어\" 방송기자클럽 ...</td>\n",
              "      <td>stalking_peak1</td>\n",
              "      <td>[\"초대받고 암호화폐 입장료 내는 구조단순 호기심으로 들어갈 수 없어\" 방송기자클럽...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2022-09-16</td>\n",
              "      <td>중앙일보</td>\n",
              "      <td>1683</td>\n",
              "      <td>신당역 \"국가가 못지켰다\"던 한동훈 \"스토킹, 합의해도 처벌\"</td>\n",
              "      <td>한동훈 법무부 장관이 신당역 스토킹 살인 범죄와 관련, 검찰에 '스토킹 범죄 엄정 ...</td>\n",
              "      <td>stalking_peak2</td>\n",
              "      <td>[한동훈 법무부 장관이 신당역 스토킹 살인 범죄와 관련, 검찰에 '스토킹 범죄 엄정...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2022-09-16</td>\n",
              "      <td>이데일리</td>\n",
              "      <td>1079</td>\n",
              "      <td>'신당역' 역무원 살해범, 위생모 쓴 이유는…'그날의 행적'</td>\n",
              "      <td>일회용 승차권으로 '신당역'까지 이동 흉기 사전에 준비철저한 '계획범죄' [이데일리...</td>\n",
              "      <td>stalking_peak2</td>\n",
              "      <td>[일회용 승차권으로 '신당역'까지 이동 흉기 사전에 준비철저한 '계획범죄' [이데일...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2022-09-15</td>\n",
              "      <td>조선일보</td>\n",
              "      <td>903</td>\n",
              "      <td>한동훈, 스토킹 살인 현장 예고없이 방문… “국가가 지켜주지 못했다”</td>\n",
              "      <td>한동훈 법무부 장관은 15일 ‘스토킹 살인 사건’이 일어난 서울 지하철 2호선 신당...</td>\n",
              "      <td>stalking_peak2</td>\n",
              "      <td>[한동훈 법무부 장관은 15일 ‘스토킹 살인 사건’이 일어난 서울 지하철 2호선 신...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2022-01-11</td>\n",
              "      <td>강원일보</td>\n",
              "      <td>365</td>\n",
              "      <td>윤석열 \"비과학적 방역패스 철회, 아동청소년 강제적 백신접종 반대\"</td>\n",
              "      <td>\"환기 잘 되는 시설엔 방역패스 필요없는 환기 등급제 적용 [속보]윤석열 \"비과학적...</td>\n",
              "      <td>nurse_peak1</td>\n",
              "      <td>[\"환기 잘 되는 시설엔 방역패스 필요없는 환기 등급제 적용 [속보]윤석열 \"비과학...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2022-01-11</td>\n",
              "      <td>조선비즈</td>\n",
              "      <td>90</td>\n",
              "      <td>간호계·의료계 충돌 중인데…이재명 “간호법 제정 적극 추진”</td>\n",
              "      <td>“간호사 관련 법률, 1951년 제정된 국민의료법 틀에 갇혀”         이재명...</td>\n",
              "      <td>nurse_peak1</td>\n",
              "      <td>[“간호사 관련 법률, 1951년 제정된 국민의료법 틀에 갇혀”         이재...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2022-01-11</td>\n",
              "      <td>파이낸셜뉴스</td>\n",
              "      <td>57</td>\n",
              "      <td>이재명·윤석열, 같은 날 \"간호법 제정 추진\" 한목소리</td>\n",
              "      <td>간호계-의사단체간 갈등 국면서 간호계 손 들어줘..국회서 처리 주목   국회사진기자...</td>\n",
              "      <td>nurse_peak1</td>\n",
              "      <td>[간호사의업무 범위에 대한해석을두고간호 계와 의사단체간의견이 충돌하 고있는가운데, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2023-05-17</td>\n",
              "      <td>경향신문</td>\n",
              "      <td>693</td>\n",
              "      <td>[속보]간호협회 “오늘부터 대리처방·수술 거부···면허증 반납하겠다”</td>\n",
              "      <td>대한간호협회는 17일 오전 기자회견을 열고 “우리 간호사는 준법투쟁을 전개할 것”이...</td>\n",
              "      <td>nurse_peak2</td>\n",
              "      <td>[대한간호협회는 17일 오전 기자회견을 열고 “우리 간호사는 준법투쟁을 전개할 것”...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2023-05-16</td>\n",
              "      <td>매일신문</td>\n",
              "      <td>603</td>\n",
              "      <td>[속보] 이재명 \"尹 간호법 거부권 행사는 민주주의 도전, 헛공약 사죄하라\"</td>\n",
              "      <td>이재명 더불어민주당 대표가 윤석열 대통령의 간호법 거부권 행사를 두고 즉각 비판했다...</td>\n",
              "      <td>nurse_peak2</td>\n",
              "      <td>[윤석열 대통령이 16일 오전 대통령실에서 진행한 국무회의에서 간호법 제정안에 대해...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2023-05-17</td>\n",
              "      <td>더팩트</td>\n",
              "      <td>480</td>\n",
              "      <td>尹대통령, `공약`한 간호법도 거부권 행사…간호사단체 \"약속 파기\"</td>\n",
              "      <td>대통령실 \"간호계 요구 귀 막고 있지 않아\" 거부권 추가 행사 관측엔 \"특수성 고려...</td>\n",
              "      <td>nurse_peak2</td>\n",
              "      <td>[대통령실 \"간호계 요구 귀 막고 있지 않아\" 거부권 추가 행사 관측엔 \"특수성 고...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-645bf8a6-4140-42c8-875f-65952e941cd5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-645bf8a6-4140-42c8-875f-65952e941cd5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-645bf8a6-4140-42c8-875f-65952e941cd5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8345e781-c155-4836-9ea6-b5a164bf6a63\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8345e781-c155-4836-9ea6-b5a164bf6a63')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8345e781-c155-4836-9ea6-b5a164bf6a63 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Summary'][2]"
      ],
      "metadata": {
        "id": "TL4_rL9WA17p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd6e330-2fae-47f9-e249-ab0dc1c4e75c"
      },
      "id": "TL4_rL9WA17p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['연합뉴스     더불어민주당 초선이자 20∼30대 의원인 오영환·이소영·장경태·장철민·전용기 의원 5명은 9일 입장문을 내 “민주당 참패 원인은 저희들을 포함한 민주당의 착각과 판에 있었음을 자인한다”고 밝혔다.',\n",
              " '이들은 국회 소통관에서 입장문을 발표하고 “이번 재보궐 선거를 치르게 된 원인이 우리 당 공직자의 성 비위 문제였음에도 불구하고 당은 당헌, 당규를 개정해 후보를 내고 피해자에 대한 제대로 된 사죄도 없었으며, 당내 2차 가해를 적극적으로 막는 조치를 취하지 않았다”며 “이 문제를 회피하고 외면할 수 있지 않을까 하는 오만함이었다”고 인정했다.',\n",
              " '그동안 민주당에서 초선 의원들이 당내 현안에 비판적인 입장을 밝힌 것은 이번이 처음으로, 패배 뒤 뒤늦은 반성이라는 지적도 나온다.']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # export results\n",
        "# df.to_excel('../2023_News/Datasets/summ/news_subset_summ.xlsx', index=False)"
      ],
      "metadata": {
        "id": "YHXCOpYGafyP"
      },
      "id": "YHXCOpYGafyP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xzza1yJBtK5N"
      },
      "id": "xzza1yJBtK5N",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "collapsed_sections": [
        "fREuuQ9-hGvZ"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
